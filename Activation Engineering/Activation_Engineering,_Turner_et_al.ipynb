{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0f1362eb5c4c4c4f84be657dd267d4e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4611b060f654482b854a231ac696f14b",
              "IPY_MODEL_772ddc92476b488c847dc248bc3d9666",
              "IPY_MODEL_ce159fba098d48cc8f5a3f436ecd139a"
            ],
            "layout": "IPY_MODEL_73d7ef4fe6f440f98b7637280d23033f"
          }
        },
        "4611b060f654482b854a231ac696f14b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a98e52581ec24d4d89106c0491bd410d",
            "placeholder": "​",
            "style": "IPY_MODEL_f059ad4dda5d4a8caec676baf4a312b0",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "772ddc92476b488c847dc248bc3d9666": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_739c55e72b2b431993a8ea8e8b830847",
            "max": 26,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6e616cbcca604102bd2a40035a94712e",
            "value": 26
          }
        },
        "ce159fba098d48cc8f5a3f436ecd139a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a87de152caa545518e29e3cedef4d2f3",
            "placeholder": "​",
            "style": "IPY_MODEL_fe7f89dbb9f64a25a3b53d50f7773e8d",
            "value": " 26.0/26.0 [00:00&lt;00:00, 2.81kB/s]"
          }
        },
        "73d7ef4fe6f440f98b7637280d23033f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a98e52581ec24d4d89106c0491bd410d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f059ad4dda5d4a8caec676baf4a312b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "739c55e72b2b431993a8ea8e8b830847": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6e616cbcca604102bd2a40035a94712e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a87de152caa545518e29e3cedef4d2f3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fe7f89dbb9f64a25a3b53d50f7773e8d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "05524ffe186a4e7cb148245d34aa0294": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7bbc75d0334e427aacebc5012d45ae5b",
              "IPY_MODEL_abb95a5dceec42f89817231fd88072b6",
              "IPY_MODEL_306c5c0df6604111b24036d292786820"
            ],
            "layout": "IPY_MODEL_6de548cffb3f449dba8a01085ab4a9ce"
          }
        },
        "7bbc75d0334e427aacebc5012d45ae5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_df21add91c5e43afaa67442de0a22d73",
            "placeholder": "​",
            "style": "IPY_MODEL_afc09ecd4d9b4229bd681843080d7c54",
            "value": "vocab.json: 100%"
          }
        },
        "abb95a5dceec42f89817231fd88072b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c642946366c243529bc941173c5a7277",
            "max": 1042301,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_dd1151824b714186b63a0b905dab9e46",
            "value": 1042301
          }
        },
        "306c5c0df6604111b24036d292786820": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dc92497c39264e9c9073b8d72abd41e2",
            "placeholder": "​",
            "style": "IPY_MODEL_4a56bbb4f9964c199d56292284e64049",
            "value": " 1.04M/1.04M [00:00&lt;00:00, 3.51MB/s]"
          }
        },
        "6de548cffb3f449dba8a01085ab4a9ce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "df21add91c5e43afaa67442de0a22d73": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "afc09ecd4d9b4229bd681843080d7c54": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c642946366c243529bc941173c5a7277": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dd1151824b714186b63a0b905dab9e46": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "dc92497c39264e9c9073b8d72abd41e2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4a56bbb4f9964c199d56292284e64049": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a053725853b64771a516f97611ffa9b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e865d59a459a4b80a5e05e32bee47ecd",
              "IPY_MODEL_7fe715ac3f8e47afb37716af10444ca6",
              "IPY_MODEL_7382b6effcb747159add64cb8b0e42e7"
            ],
            "layout": "IPY_MODEL_d3b342f603b7492280f8adb5a3fce4a9"
          }
        },
        "e865d59a459a4b80a5e05e32bee47ecd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_064d3f2572d143068a207393ea266872",
            "placeholder": "​",
            "style": "IPY_MODEL_48cbfa882d2045cb90dd2c1ed6c44112",
            "value": "merges.txt: 100%"
          }
        },
        "7fe715ac3f8e47afb37716af10444ca6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ca974d85f1cc401faf304a9332347602",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_080c0d50803f4bd0969682e82336732b",
            "value": 456318
          }
        },
        "7382b6effcb747159add64cb8b0e42e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_910ba0e128b94b60bca1bebb567485b3",
            "placeholder": "​",
            "style": "IPY_MODEL_74def5218b5446bcaca2ff1d3010d25c",
            "value": " 456k/456k [00:00&lt;00:00, 1.21MB/s]"
          }
        },
        "d3b342f603b7492280f8adb5a3fce4a9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "064d3f2572d143068a207393ea266872": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "48cbfa882d2045cb90dd2c1ed6c44112": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ca974d85f1cc401faf304a9332347602": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "080c0d50803f4bd0969682e82336732b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "910ba0e128b94b60bca1bebb567485b3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "74def5218b5446bcaca2ff1d3010d25c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d7a8aac880ab445a92bb70799a62b0a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d60f2700f95d43649620fa15a9893f39",
              "IPY_MODEL_89a368a6034645f8a7aa5e21021ebf32",
              "IPY_MODEL_57545fc9fc494540ac58a9646022cb8a"
            ],
            "layout": "IPY_MODEL_c55d3e2087164009905c7256c926f5db"
          }
        },
        "d60f2700f95d43649620fa15a9893f39": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0b262b1dd1334e37bc00ada80b76c48f",
            "placeholder": "​",
            "style": "IPY_MODEL_9425a463818c4f179436d400c7f2274f",
            "value": "tokenizer.json: 100%"
          }
        },
        "89a368a6034645f8a7aa5e21021ebf32": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f2d2b784b87146678a68e1a72f86ee8e",
            "max": 1355256,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ce7d1a0c02d447d58817c1306fd061b3",
            "value": 1355256
          }
        },
        "57545fc9fc494540ac58a9646022cb8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d09d59f2d173459b947e71432827e355",
            "placeholder": "​",
            "style": "IPY_MODEL_7fbc12363c574efeb8b47bb0773023aa",
            "value": " 1.36M/1.36M [00:00&lt;00:00, 1.89MB/s]"
          }
        },
        "c55d3e2087164009905c7256c926f5db": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0b262b1dd1334e37bc00ada80b76c48f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9425a463818c4f179436d400c7f2274f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f2d2b784b87146678a68e1a72f86ee8e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ce7d1a0c02d447d58817c1306fd061b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d09d59f2d173459b947e71432827e355": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7fbc12363c574efeb8b47bb0773023aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "69ce682b52bd4db9aab497f3eaa9c6ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7f809cd09be345219a7b2f4277162c88",
              "IPY_MODEL_ef973680f0304b1bbcc4305a8c0739ac",
              "IPY_MODEL_e5de61d569de44ca9f2588af70666e2a"
            ],
            "layout": "IPY_MODEL_3a14b8de23c24926a5ee1ef94ffb51b5"
          }
        },
        "7f809cd09be345219a7b2f4277162c88": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_83af750001294a9eb14c2728a96d578d",
            "placeholder": "​",
            "style": "IPY_MODEL_6d9c3bf45ed44ca1a8b882eff9c42f75",
            "value": "config.json: 100%"
          }
        },
        "ef973680f0304b1bbcc4305a8c0739ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1343d236a5994890a974f5bb8819f978",
            "max": 665,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a499a426dc094f9bb7ea678cefe0382b",
            "value": 665
          }
        },
        "e5de61d569de44ca9f2588af70666e2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a3c2ceff44a04f09b7bffb6dcc7194ca",
            "placeholder": "​",
            "style": "IPY_MODEL_3c69a50253db4b15ba9d5b83ab326a5a",
            "value": " 665/665 [00:00&lt;00:00, 72.3kB/s]"
          }
        },
        "3a14b8de23c24926a5ee1ef94ffb51b5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "83af750001294a9eb14c2728a96d578d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6d9c3bf45ed44ca1a8b882eff9c42f75": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1343d236a5994890a974f5bb8819f978": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a499a426dc094f9bb7ea678cefe0382b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a3c2ceff44a04f09b7bffb6dcc7194ca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3c69a50253db4b15ba9d5b83ab326a5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "623d4126a50b44db85ee8f3b6b1b35c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6aa829034a384695a05bd5f8549bd3b2",
              "IPY_MODEL_5545da7099434ac49410c5fab480c8aa",
              "IPY_MODEL_e147c0b048084a9d9d1d66becbbb54d8"
            ],
            "layout": "IPY_MODEL_e3ac963bafd0493d954ba9788c4cb05e"
          }
        },
        "6aa829034a384695a05bd5f8549bd3b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9a762f923dbb47e6af5c81f3e60491f8",
            "placeholder": "​",
            "style": "IPY_MODEL_6fffd96ba84e40d6a5212af582b6bda8",
            "value": "model.safetensors: 100%"
          }
        },
        "5545da7099434ac49410c5fab480c8aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2c1000f5d369476b93fc3177d8a099ef",
            "max": 548105171,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1b30a10c33e54ad6841b223b17e949c9",
            "value": 548105171
          }
        },
        "e147c0b048084a9d9d1d66becbbb54d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d6860c578a1445c986a44de941ac474e",
            "placeholder": "​",
            "style": "IPY_MODEL_1c2f14a66f0948b8bdac3016dfd0af58",
            "value": " 548M/548M [00:07&lt;00:00, 84.6MB/s]"
          }
        },
        "e3ac963bafd0493d954ba9788c4cb05e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9a762f923dbb47e6af5c81f3e60491f8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6fffd96ba84e40d6a5212af582b6bda8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2c1000f5d369476b93fc3177d8a099ef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1b30a10c33e54ad6841b223b17e949c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d6860c578a1445c986a44de941ac474e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1c2f14a66f0948b8bdac3016dfd0af58": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "751c3ffcf6034801a7215ab98b4f7f7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6824a93286354e0284e5db4c270551e6",
              "IPY_MODEL_9a633f89aa444a9c851118d9dc01aff8",
              "IPY_MODEL_140800cbd9ec42979b37645280a73c2d"
            ],
            "layout": "IPY_MODEL_ecdd3f79bac4493fae92e8134e1b28d8"
          }
        },
        "6824a93286354e0284e5db4c270551e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_49c8ebdc347541f5a63cdb9e545eb50c",
            "placeholder": "​",
            "style": "IPY_MODEL_792d46b7801f47b4854eb35f6b7049b1",
            "value": "generation_config.json: 100%"
          }
        },
        "9a633f89aa444a9c851118d9dc01aff8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ab69720f637f4607a1ddffec6d289812",
            "max": 124,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7c99a5487e3a48928302e0c018c0bdd0",
            "value": 124
          }
        },
        "140800cbd9ec42979b37645280a73c2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7787674831024150b7f1a113045a4e4a",
            "placeholder": "​",
            "style": "IPY_MODEL_af919d38a987481481b9e4d4853df272",
            "value": " 124/124 [00:00&lt;00:00, 13.6kB/s]"
          }
        },
        "ecdd3f79bac4493fae92e8134e1b28d8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "49c8ebdc347541f5a63cdb9e545eb50c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "792d46b7801f47b4854eb35f6b7049b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ab69720f637f4607a1ddffec6d289812": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7c99a5487e3a48928302e0c018c0bdd0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7787674831024150b7f1a113045a4e4a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "af919d38a987481481b9e4d4853df272": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "895c7c1daa5b4568acb7379fa20b16f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e39b22228f8a4f40b2faef991e03d5e2",
              "IPY_MODEL_329b024ad50644e792ec6d4b920e20c8",
              "IPY_MODEL_5aa080c103344c7fb2038c3a18e0ba59"
            ],
            "layout": "IPY_MODEL_6c6951f5bbe74cee9bbc0f9e5bc24f9e"
          }
        },
        "e39b22228f8a4f40b2faef991e03d5e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_488d09cf36494aac9613b5dc12f35a0b",
            "placeholder": "​",
            "style": "IPY_MODEL_c862dbd2f253491eb53c9c967f52ab7d",
            "value": "Loading weights: 100%"
          }
        },
        "329b024ad50644e792ec6d4b920e20c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_70408eae09ee4773a42e177d5318ed59",
            "max": 292,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_eeb2f0fba99647b0ab598e3238e0814b",
            "value": 292
          }
        },
        "5aa080c103344c7fb2038c3a18e0ba59": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d01bb3ef7eda427197540c4c01b7bc64",
            "placeholder": "​",
            "style": "IPY_MODEL_5cdb7b252f1746ca9eac7952a2dd87af",
            "value": " 292/292 [00:00&lt;00:00, 836.56it/s, Materializing param=transformer.wte.weight]"
          }
        },
        "6c6951f5bbe74cee9bbc0f9e5bc24f9e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "488d09cf36494aac9613b5dc12f35a0b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c862dbd2f253491eb53c9c967f52ab7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "70408eae09ee4773a42e177d5318ed59": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eeb2f0fba99647b0ab598e3238e0814b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d01bb3ef7eda427197540c4c01b7bc64": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5cdb7b252f1746ca9eac7952a2dd87af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**LLM steering via different methods** :\n",
        "\n",
        "1. **Intervening on weights**, as with supervised finetuning, RLHF, steerable layers, and weight editing\n",
        "(that is, targeted fine-tuning) (Ranzato et al. 2016; Ziegler et al. 2019; Dathathri et al. 2020; Meng\n",
        "et al. 2023; Ilharco et al. 2023). However, naive RLHF, finetuning, and weight editing have known\n",
        "side-effects on overall model performance (Hase et al. 2023; Qi et al. 2023; Brown et al. 2023)\n",
        "\n",
        "2.  **Intervening at decoding**, as with guided or trainable decoding (Gu et al. 2017; Grover et al. 2019;\n",
        "see Zhang et al. 2022a for an overview of controlled generation and Jin et al. 2022 for textual style\n",
        "transfer)\n",
        "\n",
        "3. **Intervening on the prompt**, as with automated prompt engineering (Shin et al. 2020; Zhou et al. 2022)\n",
        "\n",
        "4. **Intervening on token embeddings**, as with ‘soft prompting’ (Li & Liang 2021(**prefix tuning**); Lester et al. 2021(**parameter efficient promt-tuning**);\n",
        "Khashabi et al 2022) - **Li & Liang 2021** add trainable vectors to every single layer of the transformer network. Instead of just modifying the input embeddings, they modify the \"Key\" and \"Value\" matrices inside every attention block (Layer 1, Layer 2, ... Layer 12). But **Lester et al., 2021** added the trainable vector only at the input layer. And below I experimented with that.\n",
        "    \n",
        "\n",
        "5. **Intervening on activations**, for instance by freezing the weights of the LLM and searching for a\n",
        "\"steering vector\" of activations, e.g. using gradient descent (**Subramani et al. 2022** - They found \"Steering Vectors\" that act like a remote control, forcing the model to say anything they want; **Hernandez\n",
        "et al. 2023**- They could \"edit\" the model's beliefs by injecting a vector.Like they found a vector which they added to paris and then model started saying it is from Rome). These optimized extraction methods, which search for a steering vector, differ from\n",
        "extraction methods which directly compute it (present work and Li et al. 2023b). In our work, we\n",
        "do not use gradient descent or other optimization methods.\n",
        "\n"
      ],
      "metadata": {
        "id": "HHMc_l0V3w5f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# INTERVENING ON TOKEN EMBEDDINGS WITH SOFT PROMPTING"
      ],
      "metadata": {
        "id": "S-e7bVtBmeDs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "If we are using Soft Prompting : one would insert a trainable vector (virtual token) into the input. You would then need to freeze the model weights and run a search (using backpropagation/gradient descent) to optimize that vector until the model consistently outputs \"Love\" instead of \"Hate\"."
      ],
      "metadata": {
        "id": "vtIK4dTowS9T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In Soft Prompting, you intervene at that exact \"swapping\" stage. Instead of using the fixed vectors that correspond to real English words (like \"Translate\" or \"Summarize\"), you create new, tunable vectors and insert them into the input sequence.\n",
        "\n",
        "1. Virtual Tokens: These new vectors are often called \"soft prompts\" or \"virtual tokens.\" They act like words to the model, but they don't correspond to any actual word in the dictionary.\n",
        "\n",
        "2. Continuous vs. Discrete: The document notes that standard prompting is \"discrete\" (a token is either present or not). Soft prompting breaks this rule by allowing these vectors to be continuous variables that can be mathematically adjusted.\n",
        "How it is trained? - You freeze model weights, then Backpropagation: You run data through the model and measure the error. Instead of updating the model to fix the error, you update only the soft prompt vectors."
      ],
      "metadata": {
        "id": "sBpVQvpy6H0I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
        "import numpy as np\n",
        "\n",
        "print(\"Loading model.....\")\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
        "model = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n",
        "\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# creating soft promting with virtual tokens, which can be trained\n",
        "# we can create any number of virtual tokens, I am starting with 5\n",
        "num_soft_tokens = 5\n",
        "embedding_dim = model.transformer.wte.weight.shape[1]\n",
        "\n",
        "# now we will use real language tokens to initialize soft tokens from pretrained model,\n",
        "# instead of starting with random noise\n",
        "init_token_ids = tokenizer.encode(\"Love is kind and sweet\", add_special_tokens=False)[:num_soft_tokens]\n",
        "# .detatch() removes token tensors from Pytorch's computation graph, gradients will not flow back to\n",
        "# the rest of the model and we only train the soft token embeddings\n",
        "soft_token_tensor = model.transformer.wte(torch.tensor(init_token_ids)).clone().detach()\n",
        "soft_tokens = nn.Parameter(soft_token_tensor, requires_grad=True)\n",
        "\n",
        "optimizer = optim.Adam([soft_tokens], lr=0.001)\n",
        "\n",
        "data_pairs = [\n",
        "    (\"I hate you\", \"I love you\"),\n",
        "    (\"You are terrible\", \"You are wonderful\"),\n",
        "    (\"This is the worst\", \"This is the best\"),\n",
        "    (\"I am angry\", \"I am happy\"),\n",
        "    (\"Go away\", \"Come here\"),\n",
        "]\n",
        "\n",
        "print(f\"Starting training on {len(data_pairs)} pairs...\")\n",
        "model.train()\n",
        "num_epochs = 500\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    total_loss = 0.0\n",
        "    for input_text, target_text in data_pairs:\n",
        "        input_ids = tokenizer.encode(input_text, return_tensors=\"pt\")\n",
        "\n",
        "        input_embeds = model.transformer.wte(input_ids)\n",
        "        # now will prepend the soft tokens at start of the input\n",
        "        # the input shape is : [1, soft_tokens + input_len, 768]\n",
        "        combined_embeds = torch.cat(\n",
        "            [soft_tokens.unsqueeze(0), input_embeds],dim=1\n",
        "        )\n",
        "\n",
        "        target_ids = tokenizer.encode(target_text, return_tensors='pt')\n",
        "        # In a real training loop, we'd align labels carefully\n",
        "        # For this simple demo, we just check if the model predicts the first token of \"target\"\n",
        "        # based on the last token of \"input\"\n",
        "        outputs = model(inputs_embeds=combined_embeds)\n",
        "        next_token_logits = outputs.logits[0, -1, :]\n",
        "\n",
        "        target_token_id = target_ids[0, 0]\n",
        "        loss = nn.CrossEntropyLoss()(next_token_logits.unsqueeze(0), target_token_id.unsqueeze(0))\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    if (epoch+1)%10 == 0:\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs} - Loss: {total_loss:.4f}\")\n",
        "\n",
        "print(\"training finished\")\n",
        "test_input = \"I hate you\"\n",
        "input_ids = tokenizer.encode(test_input, return_tensors=\"pt\")\n",
        "inputs_embeds = model.transformer.wte(input_ids)\n",
        "\n",
        "# With Soft Prompt\n",
        "combined_embeds = torch.cat([soft_tokens.unsqueeze(0), inputs_embeds], dim=1)\n",
        "output_ids = model.generate(inputs_embeds=combined_embeds, max_new_tokens=20)\n",
        "print(f\"Input: {test_input}\")\n",
        "print(f\"Generated (with soft prompt): {tokenizer.decode(output_ids[0], skip_special_tokens=True)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "jkkjL8ZK4kox",
        "outputId": "29ba600a-b443-47db-a3d4-bc5e1298185d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading model.....\n",
            "Starting training on 5 pairs...\n",
            "Epoch 10/500 - Loss: 28.0557\n",
            "Epoch 20/500 - Loss: 18.4757\n",
            "Epoch 30/500 - Loss: 21.5718\n",
            "Epoch 40/500 - Loss: 11.5822\n",
            "Epoch 50/500 - Loss: 10.8998\n",
            "Epoch 60/500 - Loss: 11.3319\n",
            "Epoch 70/500 - Loss: 10.3483\n",
            "Epoch 80/500 - Loss: 7.7164\n",
            "Epoch 90/500 - Loss: 11.9195\n",
            "Epoch 100/500 - Loss: 8.8279\n",
            "Epoch 110/500 - Loss: 11.7682\n",
            "Epoch 120/500 - Loss: 5.3652\n",
            "Epoch 130/500 - Loss: 7.1953\n",
            "Epoch 140/500 - Loss: 5.3573\n",
            "Epoch 150/500 - Loss: 6.2203\n",
            "Epoch 160/500 - Loss: 6.0887\n",
            "Epoch 170/500 - Loss: 4.6656\n",
            "Epoch 180/500 - Loss: 2.3220\n",
            "Epoch 190/500 - Loss: 2.1286\n",
            "Epoch 200/500 - Loss: 2.0248\n",
            "Epoch 210/500 - Loss: 1.6091\n",
            "Epoch 220/500 - Loss: 10.7010\n",
            "Epoch 230/500 - Loss: 1.3873\n",
            "Epoch 240/500 - Loss: 0.4178\n",
            "Epoch 250/500 - Loss: 1.2959\n",
            "Epoch 260/500 - Loss: 0.4419\n",
            "Epoch 270/500 - Loss: 0.8415\n",
            "Epoch 280/500 - Loss: 0.4090\n",
            "Epoch 290/500 - Loss: 1.4106\n",
            "Epoch 300/500 - Loss: 1.0093\n",
            "Epoch 310/500 - Loss: 0.3949\n",
            "Epoch 320/500 - Loss: 0.2396\n",
            "Epoch 330/500 - Loss: 0.2315\n",
            "Epoch 340/500 - Loss: 1.4189\n",
            "Epoch 350/500 - Loss: 0.7132\n",
            "Epoch 360/500 - Loss: 0.0771\n",
            "Epoch 370/500 - Loss: 0.2685\n",
            "Epoch 380/500 - Loss: 1.4008\n",
            "Epoch 390/500 - Loss: 0.2493\n",
            "Epoch 400/500 - Loss: 0.1782\n",
            "Epoch 410/500 - Loss: 0.1272\n",
            "Epoch 420/500 - Loss: 0.0731\n",
            "Epoch 430/500 - Loss: 0.0736\n",
            "Epoch 440/500 - Loss: 0.3530\n",
            "Epoch 450/500 - Loss: 0.3169\n",
            "Epoch 460/500 - Loss: 0.3048\n",
            "Epoch 470/500 - Loss: 0.2575\n",
            "Epoch 480/500 - Loss: 2.2835\n",
            "Epoch 490/500 - Loss: 0.0364\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 500/500 - Loss: 0.8451\n",
            "training finished\n",
            "Input: I hate you\n",
            "Generated (with soft prompt): I love youI hate youI hate youI hate youI hate youI hate youI hate\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Above training we did with 5 datapairs, now we can use **Sentiment Analysis datasets** and filter dataset for positive examples.\n",
        "\n",
        "So, I have used **IMDb Movie Reviews dataset** which contains 50,000 reviews labeled as positive or negative.\n",
        "\n",
        "By training our **soft prompt** on thousands of positive reviews, we are effectively teaching that vector to act as a **\"positive filter\"** for the model."
      ],
      "metadata": {
        "id": "wWwif2HF00aI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from datasets import load_dataset\n",
        "import math\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "model = GPT2LMHeadModel.from_pretrained(\"gpt2\").to(device)\n",
        "\n",
        "# Freeze Model Weights\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# Preparing IMDB movie review dataset\n",
        "print(\"Downloading IMDb dataset...\")\n",
        "try:\n",
        "    dataset = load_dataset(\"imdb\", split=\"train\")\n",
        "except Exception as e:\n",
        "    print(\"Dataset download failed, using dummy data.\")\n",
        "    dataset = [{'text': \"This movie was great\", 'label': 1}] * 100\n",
        "\n",
        "print(\"Filtering for positive reviews...\")\n",
        "# Filter for positive reviews (label=1)\n",
        "# Using 3,000 samples for better generalization from the dataset\n",
        "love_dataset = dataset.filter(lambda x: x['label'] == 1).select(range(3000))\n",
        "\n",
        "class PositiveReviewDataset(Dataset):\n",
        "    def __init__(self, txt_list, tokenizer, max_length=64):\n",
        "        self.input_ids = []\n",
        "        self.attn_masks = []\n",
        "        for txt in txt_list:\n",
        "            # Enforce strict length\n",
        "            enc = tokenizer(txt, truncation=True, max_length=max_length, padding=\"max_length\", return_tensors=\"pt\")\n",
        "            self.input_ids.append(enc['input_ids'][0])\n",
        "            self.attn_masks.append(enc['attention_mask'][0])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.input_ids)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.input_ids[idx], self.attn_masks[idx]\n",
        "\n",
        "print(\"Tokenizing data (this might take a moment)...\")\n",
        "train_data = PositiveReviewDataset(love_dataset['text'], tokenizer)\n",
        "BATCH_SIZE = 16\n",
        "train_loader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True, drop_last=True)\n",
        "\n",
        "# Creating trainable soft tokens\n",
        "requested_tokens = 10\n",
        "init_text = \"The movie was absolutely wonderful and heartwarming because\"\n",
        "init_ids = tokenizer.encode(init_text, add_special_tokens=False)[:requested_tokens]\n",
        "\n",
        "soft_prompt_tensor = model.transformer.wte(torch.tensor(init_ids).to(device)).clone().detach()\n",
        "soft_prompt = nn.Parameter(soft_prompt_tensor, requires_grad=True)\n",
        "\n",
        "# Optimizer and Scheduler\n",
        "# Using a higher max_lr because soft prompts are not as sensitive as model weights\n",
        "learning_rate = 0.005\n",
        "optimizer = optim.AdamW([soft_prompt], lr=learning_rate)\n",
        "\n",
        "num_epochs = 10\n",
        "total_steps = len(train_loader) * num_epochs\n",
        "\n",
        "# OneCycleLR Scheduler: Starts low, goes high, then goes very low to converge\n",
        "scheduler = optim.lr_scheduler.OneCycleLR(\n",
        "    optimizer,\n",
        "    max_lr=0.01,\n",
        "    total_steps=total_steps,\n",
        "    pct_start=0.3  # Spend 30% of time warming up\n",
        ")\n",
        "\n",
        "# training loop\n",
        "print(f\"Starting training on {len(train_data)} samples for {num_epochs} epochs...\")\n",
        "model.train()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    total_loss = 0\n",
        "\n",
        "    for batch_idx, (input_ids, attn_masks) in enumerate(train_loader):\n",
        "        input_ids = input_ids.to(device)\n",
        "        attn_masks = attn_masks.to(device)\n",
        "\n",
        "        # A. Embed Real Input\n",
        "        inputs_embeds = model.transformer.wte(input_ids)\n",
        "\n",
        "        # B. Prepare Soft Prompt (Dynamic Size Check)\n",
        "        real_soft_len = soft_prompt.shape[0]\n",
        "        current_batch_size = input_ids.size(0)\n",
        "\n",
        "        soft_prompt_batch = soft_prompt.unsqueeze(0).expand(current_batch_size, -1, -1)\n",
        "\n",
        "        # C. Concatenate\n",
        "        combined_embeds = torch.cat([soft_prompt_batch, inputs_embeds], dim=1)\n",
        "\n",
        "        # D. Attention Mask\n",
        "        soft_prompt_mask = torch.ones((current_batch_size, real_soft_len)).to(device)\n",
        "        combined_mask = torch.cat([soft_prompt_mask, attn_masks], dim=1)\n",
        "\n",
        "        # E. Create Labels\n",
        "        labels = torch.full((current_batch_size, combined_embeds.size(1)), -100).to(device)\n",
        "        labels[:, real_soft_len:] = input_ids\n",
        "        labels[:, real_soft_len:][attn_masks == 0] = -100\n",
        "\n",
        "        # F. Forward Pass\n",
        "        outputs = model(inputs_embeds=combined_embeds, attention_mask=combined_mask)\n",
        "        logits = outputs.logits\n",
        "\n",
        "        # Shape Alignment\n",
        "        min_len = min(logits.size(1), labels.size(1))\n",
        "        logits = logits[:, :min_len, :]\n",
        "        labels = labels[:, :min_len]\n",
        "\n",
        "        # G. Shift for Next-Token Prediction\n",
        "        shift_logits = logits[..., :-1, :].contiguous()\n",
        "        shift_labels = labels[..., 1:].contiguous()\n",
        "\n",
        "        # H. Loss\n",
        "        loss = criterion(shift_logits.view(-1, shift_logits.size(-1)), shift_labels.view(-1))\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step() # Update learning rate\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        if batch_idx % 50 == 0:\n",
        "            current_lr = scheduler.get_last_lr()[0]\n",
        "            print(f\"Epoch {epoch+1} | Batch {batch_idx} | LR: {current_lr:.5f} | Loss: {loss.item():.4f}\")\n",
        "\n",
        "    avg_loss = total_loss / len(train_loader)\n",
        "    print(f\"--- Epoch {epoch+1} Completed. Avg Loss: {avg_loss:.4f} ---\")\n",
        "\n",
        "print(\"Training complete!\")\n",
        "\n",
        "# Testing\n",
        "print(\"\\n--- TESTING STEERABILITY ---\")\n",
        "test_prompts = [\"The food tasted\", \"I really think that\", \"The weather is\"]\n",
        "\n",
        "for prompt in test_prompts:\n",
        "    input_ids = tokenizer.encode(prompt, return_tensors=\"pt\").to(device)\n",
        "    inputs_embeds = model.transformer.wte(input_ids)\n",
        "\n",
        "    # Expand soft prompt\n",
        "    soft_prompt_batch = soft_prompt.unsqueeze(0)\n",
        "    combined_embeds = torch.cat([soft_prompt_batch, inputs_embeds], dim=1)\n",
        "\n",
        "    # Generate\n",
        "    output_ids = model.generate(\n",
        "        inputs_embeds=combined_embeds,\n",
        "        max_new_tokens=40,\n",
        "        pad_token_id=tokenizer.eos_token_id,\n",
        "        do_sample=True, # Add sampling for more natural text\n",
        "        temperature=0.7\n",
        "    )\n",
        "\n",
        "    print(f\"\\nInput: {prompt}\")\n",
        "    print(f\"Generated: {tokenizer.decode(output_ids[0], skip_special_tokens=True)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XfYcP1Fm4mTd",
        "outputId": "9d688dd5-9cdd-424e-89ef-897259ea46d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Downloading IMDb dataset...\n",
            "Filtering for positive reviews...\n",
            "Tokenizing data (this might take a moment)...\n",
            "Starting training on 3000 samples for 10 epochs...\n",
            "Epoch 1 | Batch 0 | LR: 0.00040 | Loss: 4.3122\n",
            "Epoch 1 | Batch 50 | LR: 0.00060 | Loss: 4.1951\n",
            "Epoch 1 | Batch 100 | LR: 0.00115 | Loss: 3.9580\n",
            "Epoch 1 | Batch 150 | LR: 0.00202 | Loss: 3.9117\n",
            "--- Epoch 1 Completed. Avg Loss: 4.1023 ---\n",
            "Epoch 2 | Batch 0 | LR: 0.00283 | Loss: 4.1465\n",
            "Epoch 2 | Batch 50 | LR: 0.00408 | Loss: 3.9980\n",
            "Epoch 2 | Batch 100 | LR: 0.00542 | Loss: 3.7321\n",
            "Epoch 2 | Batch 150 | LR: 0.00673 | Loss: 4.0362\n",
            "--- Epoch 2 Completed. Avg Loss: 3.8991 ---\n",
            "Epoch 3 | Batch 0 | LR: 0.00764 | Loss: 3.9084\n",
            "Epoch 3 | Batch 50 | LR: 0.00869 | Loss: 3.9181\n",
            "Epoch 3 | Batch 100 | LR: 0.00946 | Loss: 4.1108\n",
            "Epoch 3 | Batch 150 | LR: 0.00991 | Loss: 3.8993\n",
            "--- Epoch 3 Completed. Avg Loss: 3.8716 ---\n",
            "Epoch 4 | Batch 0 | LR: 0.01000 | Loss: 3.8531\n",
            "Epoch 4 | Batch 50 | LR: 0.00996 | Loss: 3.8847\n",
            "Epoch 4 | Batch 100 | LR: 0.00985 | Loss: 3.8225\n",
            "Epoch 4 | Batch 150 | LR: 0.00967 | Loss: 3.7836\n",
            "--- Epoch 4 Completed. Avg Loss: 3.8608 ---\n",
            "Epoch 5 | Batch 0 | LR: 0.00949 | Loss: 4.1499\n",
            "Epoch 5 | Batch 50 | LR: 0.00920 | Loss: 3.7889\n",
            "Epoch 5 | Batch 100 | LR: 0.00884 | Loss: 3.8847\n",
            "Epoch 5 | Batch 150 | LR: 0.00843 | Loss: 4.0951\n",
            "--- Epoch 5 Completed. Avg Loss: 3.8537 ---\n",
            "Epoch 6 | Batch 0 | LR: 0.00810 | Loss: 3.8693\n",
            "Epoch 6 | Batch 50 | LR: 0.00761 | Loss: 4.0513\n",
            "Epoch 6 | Batch 100 | LR: 0.00708 | Loss: 3.7739\n",
            "Epoch 6 | Batch 150 | LR: 0.00652 | Loss: 3.7624\n",
            "--- Epoch 6 Completed. Avg Loss: 3.8483 ---\n",
            "Epoch 7 | Batch 0 | LR: 0.00609 | Loss: 4.0968\n",
            "Epoch 7 | Batch 50 | LR: 0.00550 | Loss: 3.8640\n",
            "Epoch 7 | Batch 100 | LR: 0.00490 | Loss: 3.7678\n",
            "Epoch 7 | Batch 150 | LR: 0.00430 | Loss: 3.9242\n",
            "--- Epoch 7 Completed. Avg Loss: 3.8476 ---\n",
            "Epoch 8 | Batch 0 | LR: 0.00386 | Loss: 3.9013\n",
            "Epoch 8 | Batch 50 | LR: 0.00329 | Loss: 4.0344\n",
            "Epoch 8 | Batch 100 | LR: 0.00274 | Loss: 3.6803\n",
            "Epoch 8 | Batch 150 | LR: 0.00222 | Loss: 3.9785\n",
            "--- Epoch 8 Completed. Avg Loss: 3.8418 ---\n",
            "Epoch 9 | Batch 0 | LR: 0.00186 | Loss: 3.7617\n",
            "Epoch 9 | Batch 50 | LR: 0.00142 | Loss: 3.8510\n",
            "Epoch 9 | Batch 100 | LR: 0.00103 | Loss: 3.7212\n",
            "Epoch 9 | Batch 150 | LR: 0.00069 | Loss: 3.9804\n",
            "--- Epoch 9 Completed. Avg Loss: 3.8456 ---\n",
            "Epoch 10 | Batch 0 | LR: 0.00048 | Loss: 3.7045\n",
            "Epoch 10 | Batch 50 | LR: 0.00026 | Loss: 3.5658\n",
            "Epoch 10 | Batch 100 | LR: 0.00010 | Loss: 3.9574\n",
            "Epoch 10 | Batch 150 | LR: 0.00002 | Loss: 3.7113\n",
            "--- Epoch 10 Completed. Avg Loss: 3.8437 ---\n",
            "Training complete!\n",
            "\n",
            "--- TESTING STEERABILITY ---\n",
            "\n",
            "Input: The food tasted\n",
            "Generated:  very well. The first time I spent a day at the buffet at the hotel, I was just eating there. I can't wait to go back. But I also am very hungry and want to\n",
            "\n",
            "Input: I really think that\n",
            "Generated:  this was a great movie. I was surprised at how the first person I saw was not a very good person, but I got the impression that it was someone who could deal with problems. I'm\n",
            "\n",
            "Input: The weather is\n",
            "Generated:  pretty calm. Even at the beginning of the day, I was worried. The sky was blue and the sky was blue. It was cold, but then again, the day just was cold. I\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testing the above trained model with different prompts."
      ],
      "metadata": {
        "id": "0A2kfndL1yBb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_steered(input_text, max_new_tokens=50, temperature=0.7):\n",
        "    model.eval() # Set to evaluation mode\n",
        "\n",
        "    # Encode input\n",
        "    input_ids = tokenizer.encode(input_text, return_tensors=\"pt\").to(device)\n",
        "    inputs_embeds = model.transformer.wte(input_ids)\n",
        "\n",
        "    # Expand soft prompt to match batch size (which is 1 here)\n",
        "    # We assume 'soft_prompt' is available from your previous training cell\n",
        "    soft_prompt_batch = soft_prompt.unsqueeze(0)\n",
        "\n",
        "    # Concatenate: [Soft Prompt] + [User Input]\n",
        "    combined_embeds = torch.cat([soft_prompt_batch, inputs_embeds], dim=1)\n",
        "\n",
        "    # Generate\n",
        "    with torch.no_grad():\n",
        "        output_ids = model.generate(\n",
        "            inputs_embeds=combined_embeds,\n",
        "            max_new_tokens=max_new_tokens,\n",
        "            pad_token_id=tokenizer.eos_token_id,\n",
        "            do_sample=True,      # Adds variety so it's not robotic\n",
        "            temperature=temperature, # Controls creativity (0.7 is a sweet spot)\n",
        "            top_k=50             # Limits to top 50 likely words\n",
        "        )\n",
        "\n",
        "    return tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
        "\n",
        "# variours testing styles\n",
        "test_inputs = [\n",
        "    # Neutral starts\n",
        "    \"The restaurant was\",\n",
        "    \"I went to the store and\",\n",
        "\n",
        "    # Negative starts (Let's see if the prompt fights the negativity!)\n",
        "    \"I usually hate it when\",\n",
        "    \"My boss is always\",\n",
        "\n",
        "    # Random concepts\n",
        "    \"The meaning of life is\",\n",
        "    \"Tomorrow will be\"\n",
        "]\n",
        "\n",
        "print(f\"--- TESTING STEERED MODEL (Temperature: 0.7) ---\\n\")\n",
        "\n",
        "for text in test_inputs:\n",
        "    result = generate_steered(text)\n",
        "    print(f\"Input:    {text}\")\n",
        "    print(f\"Response: {result}\\n\" + \"-\"*40)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gW-wZ27L-isW",
        "outputId": "45c80a43-989f-4a88-dd22-6fe7a3d3df31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- TESTING STEERED MODEL (Temperature: 0.7) ---\n",
            "\n",
            "Input:    The restaurant was\n",
            "Response:  awesome. I've been to all three of the restaurants and they are all fantastic. I've always loved the food. The food is not overwhelming and I have never had a bad meal with it.<br /><br />This is a small restaurant\n",
            "----------------------------------------\n",
            "Input:    I went to the store and\n",
            "Response:  bought some of the original films which were released in the early '90s. I'm not sure if it was my first time seeing this film but it was one of those rare films which was well received by the people who knew what they were doing\n",
            "----------------------------------------\n",
            "Input:    I usually hate it when\n",
            "Response:  I watch movies with bad reviews because it's just not there. For one thing, the film does not do enough good to deserve its review. The characters are mostly just a bunch of people who are not really different from each other. I know how\n",
            "----------------------------------------\n",
            "Input:    My boss is always\n",
            "Response:  telling me that I should watch a movie and I am always thrilled when I see the movie! The story behind this movie is something I have seen on TV, and I could not be happier with the movie.<br /><br />I love this\n",
            "----------------------------------------\n",
            "Input:    The meaning of life is\n",
            "Response:  an extremely important one. And of course, as we know, life is not only about the meaning of life. The meaning of life is also very important in the lives of others.<br /><br />I was curious to see how this movie\n",
            "----------------------------------------\n",
            "Input:    Tomorrow will be\n",
            "Response:  a special movie for me because I'm just enjoying watching the movie. In this movie, the cast features actors, actors, and actresses of all ages. While there is a lot of humor, the characters are a little bit goofy at times. They\n",
            "----------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# INTERVENING ON ACTIVATIONS"
      ],
      "metadata": {
        "id": "-Ny1DlwBoctH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Subramani et al. (2022): \"The Sentence Reconstructor\"**\n",
        "\n",
        "\n",
        "1. **Goal**: They wanted to see if they could force a frozen model to output an exact specific sentence (e.g., \"The weather is blue\") just by injecting a vector.\n",
        "\n",
        "2. **Method**:They freeze the model.They create a random vector z.They run the model and compare the output to the target sentence.\n",
        "\n",
        "3. **Gradient Descent:** They calculate the error (loss) and use backpropagation to update the vector z (not the model weights).\n",
        "\n",
        "4. They repeat this until the vector $z$ is perfect.\n",
        "\n",
        "5. **Result:** They found \"Steering Vectors\" that act like a remote control, forcing the model to say anything they want."
      ],
      "metadata": {
        "id": "4HMjIEtCoor7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 1. SETUP\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "model = GPT2LMHeadModel.from_pretrained(\"gpt2\").to(device)\n",
        "\n",
        "# Now freezing the model. We are not training the model. We are finding the vector\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "model.eval() # Set to eval mode (dropout off, etc.)\n",
        "\n",
        "# 2. CONFIGURATION\n",
        "# we are making the model to generate exactly this\n",
        "target_sentence = \"The weather is blue and the sky is green\"\n",
        "target_ids = tokenizer.encode(target_sentence, return_tensors=\"pt\").to(device)\n",
        "print(f\"Target sentence: '{target_sentence}'\")\n",
        "print(f\"Target IDs: {target_ids}\")\n",
        "print(f\"Target Length: {target_ids.shape[1]} tokens\")\n",
        "\n",
        "# GPT2 has no pad token by default, Loss computation expects padding to be masked out\n",
        "#\n",
        "attention_mask = torch.ones(target_ids.shape, device=device)\n",
        "\n",
        "# 3. LETS INJECT THE STEERING VECTOR OF SHAPE [1,1,768] FOR GPT2-SMALL\n",
        "# We broadcast it across the sequence length, or add it to the first token.\n",
        "# Subramani et al. often add it to all positions or specific layers.\n",
        "embedding_dim = model.config.n_embd\n",
        "steering_vector = nn.Parameter(torch.randn(1,1,embedding_dim).to(device), requires_grad=True)\n",
        "\n",
        "# making optimizer only touch the steering vector\n",
        "optimizer = optim.Adam([steering_vector], lr=0.1)\n",
        "\n",
        "# We use a mutable container to track if the hook fires\n",
        "hook_stats = {\"fired\": False}\n",
        "\n",
        "# Now intervention via hook\n",
        "# The below function will run inside the model, during forward pass\n",
        "def steering_hook(module, input, output):\n",
        "    hook_stats[\"fired\"] = True\n",
        "    # GPT-2 Blocks return a tuple: (hidden_states, present_key_values, ...)\n",
        "    hidden_states = output[0]\n",
        "    modified_hidden = hidden_states + steering_vector\n",
        "    return (modified_hidden, ) + output[1:]\n",
        "\n",
        "# we attach the hook to middle layers, because research shows middle layers are best\n",
        "# to control high-level concepts best. We are adding our hook to the outputs of 6th layer\n",
        "layer_idx = 6\n",
        "hook_handle = model.transformer.h[layer_idx].register_forward_hook(steering_hook)\n",
        "\n",
        "# performing Gradient descent to optimize the vector\n",
        "num_steps = 200\n",
        "loss_history = []\n",
        "\n",
        "print(\"Starting optimization...\")\n",
        "for step in range(num_steps):\n",
        "    optimizer.zero_grad()\n",
        "    hook_stats[\"fired\"] = False # Flag reset\n",
        "\n",
        "    # We feed the model with target_ids, model predicts the token at every position\n",
        "    # Then we compute the loss for those prediction and try to reduce them\n",
        "    outputs = model(input_ids=target_ids, attention_mask=attention_mask, labels=target_ids)\n",
        "    loss = outputs.loss\n",
        "    loss.backward()\n",
        "    # Checking if gradients exist\n",
        "    if step == 0:\n",
        "        if not hook_stats[\"fired\"]:\n",
        "            print(\"!!! ERROR: Hook did not fire. Check layer index.\")\n",
        "        if steering_vector.grad is None or steering_vector.grad.norm() == 0:\n",
        "            print(\"!!! ERROR: Zero Gradients. The graph is broken.\")\n",
        "        else:\n",
        "            print(f\"Diagnostics Pass: Hook fired. Gradient norm: {steering_vector.grad.norm().item():.4f}\")\n",
        "\n",
        "    optimizer.step()\n",
        "\n",
        "    loss_history.append(loss.item())\n",
        "    if step % 20 ==0 :\n",
        "        print(f\"Step {step} | Loss: {loss.item():.4f}\")\n",
        "\n",
        "print(\"Optimization complete!\")\n",
        "hook_handle.remove()\n",
        "\n",
        "# 4.GENERATION/VERIFICATION\n",
        "print(\"Testing whether we can predict the target\")\n",
        "\n",
        "# re-attaching the hook for verification\n",
        "hook_handle = model.transformer.h[layer_idx].register_forward_hook(steering_hook)\n",
        "\n",
        "# Start with just the first word \"The\"\n",
        "start_input = tokenizer.encode(\"The\", return_tensors=\"pt\").to(device)\n",
        "\n",
        "# We set max_length to match the target length approx\n",
        "output_ids = model.generate(\n",
        "    start_input,\n",
        "    max_new_tokens=10,\n",
        "    pad_token_id=tokenizer.eos_token_id,\n",
        "    do_sample=False # Greedy\n",
        ")\n",
        "\n",
        "generated_text = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
        "print(f\"Target:    {target_sentence}\")\n",
        "print(f\"Generated: {generated_text}\")\n",
        "\n",
        "#plotting loss to show convergence\n",
        "plt.plot(loss_history)\n",
        "plt.title(\"Sterring vector optimization loss\")\n",
        "plt.xlabel(\"Step\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.show()\n",
        "\n",
        "hook_handle.remove()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "0f1362eb5c4c4c4f84be657dd267d4e1",
            "4611b060f654482b854a231ac696f14b",
            "772ddc92476b488c847dc248bc3d9666",
            "ce159fba098d48cc8f5a3f436ecd139a",
            "73d7ef4fe6f440f98b7637280d23033f",
            "a98e52581ec24d4d89106c0491bd410d",
            "f059ad4dda5d4a8caec676baf4a312b0",
            "739c55e72b2b431993a8ea8e8b830847",
            "6e616cbcca604102bd2a40035a94712e",
            "a87de152caa545518e29e3cedef4d2f3",
            "fe7f89dbb9f64a25a3b53d50f7773e8d",
            "05524ffe186a4e7cb148245d34aa0294",
            "7bbc75d0334e427aacebc5012d45ae5b",
            "abb95a5dceec42f89817231fd88072b6",
            "306c5c0df6604111b24036d292786820",
            "6de548cffb3f449dba8a01085ab4a9ce",
            "df21add91c5e43afaa67442de0a22d73",
            "afc09ecd4d9b4229bd681843080d7c54",
            "c642946366c243529bc941173c5a7277",
            "dd1151824b714186b63a0b905dab9e46",
            "dc92497c39264e9c9073b8d72abd41e2",
            "4a56bbb4f9964c199d56292284e64049",
            "a053725853b64771a516f97611ffa9b7",
            "e865d59a459a4b80a5e05e32bee47ecd",
            "7fe715ac3f8e47afb37716af10444ca6",
            "7382b6effcb747159add64cb8b0e42e7",
            "d3b342f603b7492280f8adb5a3fce4a9",
            "064d3f2572d143068a207393ea266872",
            "48cbfa882d2045cb90dd2c1ed6c44112",
            "ca974d85f1cc401faf304a9332347602",
            "080c0d50803f4bd0969682e82336732b",
            "910ba0e128b94b60bca1bebb567485b3",
            "74def5218b5446bcaca2ff1d3010d25c",
            "d7a8aac880ab445a92bb70799a62b0a1",
            "d60f2700f95d43649620fa15a9893f39",
            "89a368a6034645f8a7aa5e21021ebf32",
            "57545fc9fc494540ac58a9646022cb8a",
            "c55d3e2087164009905c7256c926f5db",
            "0b262b1dd1334e37bc00ada80b76c48f",
            "9425a463818c4f179436d400c7f2274f",
            "f2d2b784b87146678a68e1a72f86ee8e",
            "ce7d1a0c02d447d58817c1306fd061b3",
            "d09d59f2d173459b947e71432827e355",
            "7fbc12363c574efeb8b47bb0773023aa",
            "69ce682b52bd4db9aab497f3eaa9c6ad",
            "7f809cd09be345219a7b2f4277162c88",
            "ef973680f0304b1bbcc4305a8c0739ac",
            "e5de61d569de44ca9f2588af70666e2a",
            "3a14b8de23c24926a5ee1ef94ffb51b5",
            "83af750001294a9eb14c2728a96d578d",
            "6d9c3bf45ed44ca1a8b882eff9c42f75",
            "1343d236a5994890a974f5bb8819f978",
            "a499a426dc094f9bb7ea678cefe0382b",
            "a3c2ceff44a04f09b7bffb6dcc7194ca",
            "3c69a50253db4b15ba9d5b83ab326a5a",
            "623d4126a50b44db85ee8f3b6b1b35c2",
            "6aa829034a384695a05bd5f8549bd3b2",
            "5545da7099434ac49410c5fab480c8aa",
            "e147c0b048084a9d9d1d66becbbb54d8",
            "e3ac963bafd0493d954ba9788c4cb05e",
            "9a762f923dbb47e6af5c81f3e60491f8",
            "6fffd96ba84e40d6a5212af582b6bda8",
            "2c1000f5d369476b93fc3177d8a099ef",
            "1b30a10c33e54ad6841b223b17e949c9",
            "d6860c578a1445c986a44de941ac474e",
            "1c2f14a66f0948b8bdac3016dfd0af58",
            "751c3ffcf6034801a7215ab98b4f7f7d",
            "6824a93286354e0284e5db4c270551e6",
            "9a633f89aa444a9c851118d9dc01aff8",
            "140800cbd9ec42979b37645280a73c2d",
            "ecdd3f79bac4493fae92e8134e1b28d8",
            "49c8ebdc347541f5a63cdb9e545eb50c",
            "792d46b7801f47b4854eb35f6b7049b1",
            "ab69720f637f4607a1ddffec6d289812",
            "7c99a5487e3a48928302e0c018c0bdd0",
            "7787674831024150b7f1a113045a4e4a",
            "af919d38a987481481b9e4d4853df272"
          ]
        },
        "id": "nN55Pk2Tr6bC",
        "outputId": "9915bfe0-ee82-4dee-8457-3c3c60b29ee1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0f1362eb5c4c4c4f84be657dd267d4e1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "05524ffe186a4e7cb148245d34aa0294"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a053725853b64771a516f97611ffa9b7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d7a8aac880ab445a92bb70799a62b0a1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "69ce682b52bd4db9aab497f3eaa9c6ad"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "623d4126a50b44db85ee8f3b6b1b35c2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "751c3ffcf6034801a7215ab98b4f7f7d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Target sentence: 'The weather is blue and the sky is green'\n",
            "Target IDs: tensor([[ 464, 6193,  318, 4171,  290,  262, 6766,  318, 4077]],\n",
            "       device='cuda:0')\n",
            "Target Length: 9 tokens\n",
            "Starting optimization...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`loss_type=None` was set in the config but it is unrecognized. Using the default loss: `ForCausalLMLoss`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Diagnostics Pass: Hook fired. Gradient norm: 0.1353\n",
            "Step 0 | Loss: 3.3550\n",
            "Step 20 | Loss: 0.4719\n",
            "Step 40 | Loss: 0.0183\n",
            "Step 60 | Loss: 0.0053\n",
            "Step 80 | Loss: 0.0033\n",
            "Step 100 | Loss: 0.0026\n",
            "Step 120 | Loss: 0.0022\n",
            "Step 140 | Loss: 0.0019\n",
            "Step 160 | Loss: 0.0017\n",
            "Step 180 | Loss: 0.0015\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimization complete!\n",
            "Testing whether we can predict the target\n",
            "Target:    The weather is blue and the sky is green\n",
            "Generated: The weather is blue and the sky is green and the\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Hernandez et al. (2023): \"The Knowledge Editor\"**\n",
        "\n",
        "\n",
        "*   **Goal**: They wanted to find where facts (like \"Paris is in France\") are stored and edit them (make the model think \"Paris is in Rome\").\n",
        "*   **Method**:\n",
        "\n",
        "\n",
        "1.   They realized that relationships (like City $\\to$ Country) often look like straight lines (linear) in the activation space.\n",
        "2.   Gradient Descent (Jacobian): They used the model's gradients (specifically the derivative of the output with respect to the input) to mathematically calculate the \"direction\" of that fact.\n",
        "3.   They found a vector that, when added to \"Paris\", shifts the activations to land on \"Rome\".\n",
        "\n",
        "\n",
        "*   **Result:** They could \"edit\" the model's beliefs by injecting this vector.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "3uF_7ArCZrS7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Experiment :\n",
        "\n",
        "\n",
        "1.   **The Prompt**: \"The Eiffel Tower is in\" (Model expects \"France\").\n",
        "2.   **The Goal**: Edit the model to believe it is in \"Rome\".\n",
        "3.   **The Calculation**: Instead of training, we run one pass. We calculate the gradient of the word \"Rome\" with respect to the activations. This tells us: \"Which direction do I push the neurons to make 'Rome' the most likely next word?\"\n",
        "4.   **The Injection**: We freeze the model and add this gradient vector (scaled) to the activation during inference.\n",
        "\n"
      ],
      "metadata": {
        "id": "Q6u2RXCbgybM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "# --- 1. SETUP ---\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "print(\"Loading model...\")\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2-medium\")\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "model = GPT2LMHeadModel.from_pretrained(\"gpt2-medium\").to(device)\n",
        "model.eval()\n",
        "\n",
        "# Freeze GPT-2\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# --- 2. CREATE A \"FORCED\" TRAINING DATASET ---\n",
        "# We use GENERIC prompts. The model relies 100% on the editor to know the city.\n",
        "cities = [\" Rome\", \" Paris\", \" London\", \" Tokyo\", \" Berlin\", \" Moscow\", \" Madrid\", \" Athens\", \" Beijing\", \" Cairo\"]\n",
        "templates = [\n",
        "    \"The city is\",\n",
        "    \"It is located in\",\n",
        "    \"The capital is\",\n",
        "    \"This place is in\",\n",
        "    \"We are traveling to\"\n",
        "]\n",
        "\n",
        "training_data = []\n",
        "for city in cities:\n",
        "    for temp in templates:\n",
        "        training_data.append((temp, city))\n",
        "\n",
        "print(f\"Created {len(training_data)} generic training pairs.\")\n",
        "\n",
        "class GenericDataset(Dataset):\n",
        "    def __init__(self, data, tokenizer):\n",
        "        self.data = []\n",
        "        for prompt, target in data:\n",
        "            prompt_ids = tokenizer.encode(prompt, return_tensors=\"pt\")[0]\n",
        "            target_id = tokenizer.encode(target)[0]\n",
        "            self.data.append((prompt_ids, target_id))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.data[idx]\n",
        "\n",
        "train_loader = DataLoader(GenericDataset(training_data, tokenizer), batch_size=1, shuffle=True)\n",
        "\n",
        "# --- 3. DEFINE THE REMEDI EDITOR ---\n",
        "class REMEDIEditor(nn.Module):\n",
        "    def __init__(self, embedding_dim):\n",
        "        super().__init__()\n",
        "        # Map Attribute Embedding -> Steering Vector\n",
        "        # We use a 2-layer MLP for better expressiveness than a simple linear map\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(embedding_dim, embedding_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(embedding_dim, embedding_dim)\n",
        "        )\n",
        "\n",
        "    def forward(self, attr_embedding):\n",
        "        return self.net(attr_embedding)\n",
        "\n",
        "editor = REMEDIEditor(model.config.n_embd).to(device)\n",
        "optimizer = optim.Adam(editor.parameters(), lr=1e-3)\n",
        "\n",
        "# --- 4. TRAIN THE EDITOR ---\n",
        "# Layer 12 is the sweet spot for injecting facts in GPT-2 Medium\n",
        "layer_target = 12\n",
        "\n",
        "print(f\"\\n--- TRAINING REMEDI EDITOR (Layer {layer_target}) ---\")\n",
        "num_epochs = 15\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    total_loss = 0\n",
        "    for prompt_ids, target_id in train_loader:\n",
        "        prompt_ids = prompt_ids.to(device)\n",
        "        target_id = target_id.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # A. Get Hidden State of Generic Prompt\n",
        "        with torch.no_grad():\n",
        "            outputs = model(prompt_ids, output_hidden_states=True)\n",
        "            # Hidden state at layer 12\n",
        "            h_context = outputs.hidden_states[layer_target][:, -1, :]\n",
        "\n",
        "        # B. Get Attribute Embedding (e.g., \"Rome\")\n",
        "        with torch.no_grad():\n",
        "            h_attr = model.transformer.wte(target_id)\n",
        "\n",
        "        # C. Generate Steering Vector\n",
        "        steering_vector = editor(h_attr)\n",
        "\n",
        "        # D. Combine (The REMEDI Step)\n",
        "        # We simulate the injection: Context + Vector\n",
        "        h_edited = h_context + steering_vector\n",
        "\n",
        "        # E. Pass through REST of the model to get predictions\n",
        "        # We need a helper to run the model from Layer 12 onwards\n",
        "        # But for simplicity in this script, we can map h_edited directly to logits using the head?\n",
        "        # No, GPT-2 has layers 13-24 left.\n",
        "        # TRICK: We approximate the loss by checking if the vector aligns with the target embedding\n",
        "        # Or better: We assume the vector *is* the activation shift needed.\n",
        "\n",
        "        # Robust Method: We need to pass h_edited through the rest of the model.\n",
        "        # Since we can't easily chop the model in HuggingFace, we will use a Hook-based training step.\n",
        "\n",
        "        # --- HOOK-BASED TRAINING STEP ---\n",
        "        def train_hook(module, input, output):\n",
        "            # Inject our vector during the forward pass\n",
        "            # We add it to the output of the layer\n",
        "            output[0][:, -1, :] = output[0][:, -1, :] + steering_vector\n",
        "            return output\n",
        "\n",
        "        # Attach hook\n",
        "        h_handle = model.transformer.h[layer_target].register_forward_hook(train_hook)\n",
        "\n",
        "        # Forward pass with injection\n",
        "        out_train = model(prompt_ids)\n",
        "        logits = out_train.logits[:, -1, :]\n",
        "\n",
        "        loss = nn.CrossEntropyLoss()(logits, target_id)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        h_handle.remove() # Crucial cleanup\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    if (epoch+1) % 5 == 0:\n",
        "        print(f\"Epoch {epoch+1} | Loss: {total_loss/len(train_loader):.4f}\")\n",
        "\n",
        "print(\"Training complete!\")\n",
        "\n",
        "# --- 5. TEST THE EDITOR ---\n",
        "print(\"\\n--- TESTING ON COUNTER-FACTUAL ---\")\n",
        "# Now we apply the learned editor to the specific \"Eiffel Tower\" case\n",
        "test_prompt = \"The Eiffel Tower is in\"\n",
        "target_attr = \" Rome\"\n",
        "\n",
        "input_ids = tokenizer.encode(test_prompt, return_tensors=\"pt\").to(device)\n",
        "attr_id = tokenizer.encode(target_attr, return_tensors=\"pt\")[0].to(device)\n",
        "\n",
        "# 1. Get the Vector from Editor\n",
        "with torch.no_grad():\n",
        "    h_attr = model.transformer.wte(attr_id)\n",
        "    final_steering_vector = editor(h_attr)\n",
        "    print(f\"Steering Vector Norm: {final_steering_vector.norm().item():.2f}\")\n",
        "\n",
        "# 2. Define Hook for Inference\n",
        "def inference_hook(module, input, output):\n",
        "    # We might need to scale it up because \"Eiffel Tower\" is a stronger context than \"The city is\"\n",
        "    # Try strength 5.0 to 10.0\n",
        "    strength = 10.0\n",
        "    output[0][:, -1, :] += (final_steering_vector * strength)\n",
        "    return output\n",
        "\n",
        "# 3. Generate\n",
        "hook_handle = model.transformer.h[layer_target].register_forward_hook(inference_hook)\n",
        "\n",
        "print(f\"Prompt: {test_prompt}\")\n",
        "output_ids = model.generate(input_ids, max_new_tokens=15, pad_token_id=tokenizer.eos_token_id, do_sample=False)\n",
        "res = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
        "print(f\"Result: {res}\")\n",
        "\n",
        "hook_handle.remove()\n",
        "\n",
        "# 4. Control Check\n",
        "control_ids = model.generate(input_ids, max_new_tokens=15, pad_token_id=tokenizer.eos_token_id)\n",
        "print(f\"Control: {tokenizer.decode(control_ids[0], skip_special_tokens=True)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HdVyaIo6ZlY4",
        "outputId": "2addfab1-817b-4a72-8ea3-90ee3f09b6ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Loading model...\n",
            "Created 50 generic training pairs.\n",
            "\n",
            "--- TRAINING REMEDI EDITOR (Layer 12) ---\n",
            "Epoch 5 | Loss: 0.0012\n",
            "Epoch 10 | Loss: 0.0002\n",
            "Epoch 15 | Loss: 0.0001\n",
            "Training complete!\n",
            "\n",
            "--- TESTING ON COUNTER-FACTUAL ---\n",
            "Steering Vector Norm: 165.39\n",
            "Prompt: The Eiffel Tower is in\n",
            "Result: The Eiffel Tower is in Rome Rome Rome Rome Rome Rome Rome Rome Rome Rome Rome Rome Rome Rome Rome\n",
            "Control: The Eiffel Tower is in Paris, France. The Eiffel Tower is in Paris, France.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This has worked to say Rome, but this looks like adding an additional neural net and training it to say Rome"
      ],
      "metadata": {
        "id": "Q9ZPRNmjZce6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Summary of Li et al. 2023b: Inference-Time Intervention (ITI)**"
      ],
      "metadata": {
        "id": "fhwgtm6bKcFK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Central observation - **\"knowing vs telling gap\"**\n",
        "\n",
        "\n",
        "*   Li et al. argue that models sometimes contain truth-relevant information internally but fail to express it in outputs.\n",
        "*   A> **generation accuracy** (what the model answers), and B> **probe accuracy** (how well a classifier predicts truthfulness from internal activations).\n",
        "*   On **TruthfulQA,** they report a large gap (≈40% in their LLaMA‑7B setup), suggesting internal representations can be much more truth-aware than outputs.\n",
        "\n",
        "**About TruthfulQA dataset** -\n",
        "\n",
        "The benchmark comprises questions that span 38 categories, including health, law, finance and politics.\n",
        "\n",
        "**Data Fields**\n",
        "\n",
        "* Type: Adversarial v Non-Adversarial Questions\n",
        "* Category: Category of misleading question\n",
        "* Question: The question\n",
        "* Best Answer: The best correct answer\n",
        "* Correct Answers: A set of correct answers. Delimited by ;.\n",
        "* Incorrect Answers: set of incorrect answers.Delimited by ;\n",
        "* Source: A source that supports the correct answers.\n",
        "\n",
        "**Some other key findings**\n",
        "\n",
        "*  some attention heads linearly encode truthfulness\n",
        "*  They probe attention head activations (at the last token of the concatenated Q+A) with a linear classifier per head per layer.\n",
        "*  Most heads are near chance, but a subset are highly predictive; they show strong head specialization across layers.\n",
        "*  They also show “truthfulness” isn’t just one line; it looks like a subspace (they build an orthogonal second probe direction for visualization).\n",
        "\n",
        "**Method**\n",
        "\n",
        "1.   Rank heads by probe accuracy; select top‑K.\n",
        "2.   For each selected head, define a truth direction (probe weight or mean-difference direction).\n",
        "3.   During inference, add ασθ\\alpha \\sigma \\thetaασθ to those head activations, where σ\\sigmaσ is the standard deviation along that direction.\n",
        "4.   Repeat autoregressively for each generated token.\n",
        "\n",
        "**Results**\n",
        "\n",
        "*  ITI substantially improves TruthfulQA performance (they emphasize a large boost, including on instruction-tuned variants).\n",
        "*  The method is minimally invasive, computationally cheap, and adjustable via α\\alphaα.\n",
        "*  They observe a truthfulness ↔ helpfulness tradeoff, controllable by intervention strength.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "o8YfCX4JPYe-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "1.   Locate where truthfullness is linearly represented\n",
        "2.   Then train linear probes on internal activations(specifically , attention head activations) to classify whether a (question, answer) pair is truthful or false - because we will be using TruthfulQA\n",
        "3.   Compute a “truthful direction” directly (no optimization loop at inference like subramani et al) - mean shift direction (difference between the means of truthful vs false activations)\n",
        "4.   Apply that shift during inference, on a small set of heads\n",
        "5.   During inference, they shift activations along truth-correlated directions for the top‑K heads, with strength α scaled by the activation standard deviation.\n",
        "This intervention is repeated autoregressively for each generated token.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "jnjSdvRhKyCW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Experiment to test Li et al. 2023b claims + Colab PyTorch code**\n",
        "\n",
        "What we will test?\n",
        "\n",
        "*  **Test 1 - \"truthfulness is linearly decodable internally\"** - Train a linear probe on internal activations to classify truthful vs false answer options.\n",
        "Measure probe accuracy vs baseline generation\n",
        "\n",
        "*  **Test 2 -** **“shifting activations along a truth direction improves truthfulness”** - Apply an ITI-like activation shift during scoring and see if TruthfulQA multiple-choice accuracy increases\n",
        "\n",
        "*  **Test 3 - “there’s a tunable tradeoff (strength α)”**- Sweep α\\alpha and plot TruthfulQA accuracy vs a “capability preservation” proxy (e.g., perplexity on WikiText-2 or average logprob).\n",
        "\n"
      ],
      "metadata": {
        "id": "FJcJ3xBsV67z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install transformers datasets accelerate\n",
        "\n",
        "import types\n",
        "import random\n",
        "import numpy as np\n",
        "from dataclasses import dataclass\n",
        "from typing import List, Tuple\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from datasets import load_dataset\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "SEED = 0\n",
        "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED)\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Device:\", device)\n",
        "\n",
        "\n",
        "MODEL_NAME = \"gpt2-medium\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "#In transformer models, attention is the most expensive and sensitive part of the computation.\n",
        "# Over time, Hugging Face added multiple attention backends, each with different tradeoffs,\n",
        "# like speed, memory usage, GPU support, numerical stability, pytorch compatability.\n",
        "# attention_implementation = eager means — just do attention the normal PyTorch way\n",
        "try:\n",
        "    model = AutoModelForCausalLM.from_pretrained(\n",
        "        MODEL_NAME,\n",
        "        attn_implementation=\"eager\"\n",
        "    ).to(device)\n",
        "except TypeError:\n",
        "    model = AutoModelForCausalLM.from_pretrained(MODEL_NAME).to(device)\n",
        "\n",
        "model.eval()\n",
        "\n",
        "n_layers = len(model.transformer.h)\n",
        "n_heads = model.config.n_head\n",
        "d_model = model.config.n_embd\n",
        "head_dim = d_model // n_heads\n",
        "print(f\"Layers={n_layers}, Heads={n_heads}, d_model={d_model}, head_dim={head_dim}\")\n",
        "\n",
        "# Dataset: TruthfulQA multiple_choice\n",
        "# HF provides only validation split for this config\n",
        "full_ds = load_dataset(\"truthful_qa\", \"multiple_choice\", split=\"validation\")\n",
        "splits = full_ds.train_test_split(test_size=0.30, seed=SEED, shuffle=True)\n",
        "train_q = splits[\"train\"]\n",
        "test_q = splits[\"test\"]\n",
        "print(\"Questions train:\", len(train_q), \"test:\", len(test_q))\n",
        "\n",
        "# Probe examples from MC1\n",
        "@dataclass\n",
        "class ProbeExample:\n",
        "    text: str\n",
        "    y: int\n",
        "\n",
        "def build_probe_examples(question_ds, n_questions=300, target_key=\"mc1_targets\", seed=0) -> List[ProbeExample]:\n",
        "    rng = random.Random(seed)\n",
        "    idxs = list(range(len(question_ds)))\n",
        "    rng.shuffle(idxs)\n",
        "    idxs = idxs[:min(n_questions, len(question_ds))]\n",
        "\n",
        "    out = []\n",
        "    for i in idxs:\n",
        "        ex = question_ds[i]\n",
        "        q = ex[\"question\"]\n",
        "        prompt = f\"Q: {q}\\nA:\"\n",
        "        choices = ex[target_key][\"choices\"]\n",
        "        labels = ex[target_key][\"labels\"]\n",
        "        for c, lab in zip(choices, labels):\n",
        "            out.append(ProbeExample(text=prompt + \" \" + c.strip(), y=int(lab)))\n",
        "    rng.shuffle(out)\n",
        "    return out\n",
        "\n",
        "probe_examples = build_probe_examples(train_q, n_questions=300, seed=SEED)\n",
        "print(\"Probe examples:\", len(probe_examples), \"Pos rate:\", np.mean([e.y for e in probe_examples]))\n",
        "\n",
        "# Split probe examples into probe-train/probe-val for head ranking\n",
        "idx = np.arange(len(probe_examples))\n",
        "np.random.shuffle(idx)\n",
        "split = int(0.8 * len(idx))\n",
        "probe_train = [probe_examples[i] for i in idx[:split]]\n",
        "probe_val = [probe_examples[i] for i in idx[split:]]\n",
        "print(\"Probe train:\", len(probe_train), \"Probe val:\", len(probe_val))\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# ITI(Inference tim intervention) State\n",
        "# ITIState is a global controller that remembers attention head activations, stores learned intervention\n",
        "# directions, and decides when and how strongly to nudge selected attention heads during inference.\n",
        "class ITIState:\n",
        "    def __init__(self, n_layers, n_heads, head_dim):\n",
        "        self.n_layers = n_layers\n",
        "        self.n_heads = n_heads\n",
        "        self.head_dim = head_dim\n",
        "\n",
        "        # Runtime switches\n",
        "        self.collect = False # Whether to record head activations\n",
        "        self.active = False  # Whether to apply ITI intervention\n",
        "        self.alpha = 0.0     # Strength of the intervention\n",
        "        # During probing → collect = True & During inference → active = True\n",
        "\n",
        "        # Learned ITI parameters\n",
        "        self.theta = None   # [L,H,D] - Unit direction for each head (probe weight direction)\n",
        "        self.sigma = None    # [L,H] - Std dev of projection along theta\n",
        "        self.selected = None # [L,H] - Which heads are allowed to be intervened on\n",
        "\n",
        "        # One list per layer in the shape [B,H,D], later concatenated as [N,L,H,D]\n",
        "        self._cache = [[] for _ in range(n_layers)]\n",
        "\n",
        "    # FIX: These must be real class methods (not nested inside __init__)\n",
        "    def reset_cache(self):\n",
        "        self._cache = [[] for _ in range(self.n_layers)]\n",
        "\n",
        "    # Patched attention forward\n",
        "    # Receives per-layer head outputs: [B,H,D] -> Detaches from computation graph\n",
        "    # Moves to CPU (saves GPU memory) -> Appends to that layer’s cache\n",
        "    def push(self, layer_idx, vec_bhd):\n",
        "        self._cache[layer_idx].append(vec_bhd.detach().cpu())\n",
        "\n",
        "    # Build final activation tensor\n",
        "    def pop_all(self):\n",
        "        layers = []\n",
        "        for l in range(self.n_layers):\n",
        "            # Each entry was [B,H,D] -> After concat [N,H,D]\n",
        "            x = torch.cat(self._cache[l], dim=0) if len(self._cache[l]) else torch.empty(0, self.n_heads, self.head_dim)\n",
        "            layers.append(x) # [N, H, D] pre layer\n",
        "        return torch.stack(layers, dim=1)  # [N, L, H, D], n- no of probe examples\n",
        "\n",
        "iti = ITIState(n_layers, n_heads, head_dim)\n",
        "\n",
        "# Some HELPER functions\n",
        "\n",
        "def split_heads(x, n_heads, head_dim):\n",
        "    # x: [B, T, d_model] -> [B, H, T, D] ( T is sequence length/ no of tokens)\n",
        "    B, T, C = x.shape\n",
        "    return x.view(B, T, n_heads, head_dim).permute(0, 2, 1, 3).contiguous()\n",
        "    # contiguous ensures tensor is laid out correctly in memory\n",
        "\n",
        "def merge_heads(x):\n",
        "    # x: [B, H, T, D] -> [B, T, d_model]\n",
        "    B, H, T, D = x.shape\n",
        "    return x.permute(0, 2, 1, 3).contiguous().view(B, T, H * D)\n",
        "\n",
        "# In normal causal mask -> Tq == Tk == sequence length -> Mask is simple lower traingle\n",
        "# In cached causal mask -> Tk = past_tokens + current_tokens and Tq = current_tokens only\n",
        "\n",
        "def make_causal_mask(Tq, Tk, device):\n",
        "    # For cached attention, keys are longer than queries\n",
        "    # Allow each query position to attend to all keys upto its aligned positioninthe full key sequence\n",
        "    # Q positions corresponds to last Tq keys: offset = Tk - Tq\n",
        "    qpos = torch.arange(Tq, device=device) + (Tk - Tq)\n",
        "    kpos = torch.arange(Tk, device=device)\n",
        "    # PyTorch broadcasting\n",
        "    mask = kpos[None, :] <= qpos[:, None]  #[Tq, Tk]\n",
        "    return mask\n",
        "    # For [2,5] shape, mask looks something like this, mask =\n",
        "    # [\n",
        "    #   [ True, True, True, True, False ],\n",
        "    #   [ True, True, True, True, True  ]]\n",
        "\n",
        "def expand_attention_mask(attention_mask, dtype):\n",
        "\n",
        "    if attention_mask is None:\n",
        "        return None\n",
        "\n",
        "    if attention_mask.dim() == 2:\n",
        "        # [B,T] -> additive [B,1,1,T]\n",
        "        # keep=1 => add 0, pad=0 => add -inf\n",
        "        am = attention_mask.to(dtype=dtype)\n",
        "        am = (1.0 - am) * torch.finfo(dtype).min\n",
        "        return am[:, None, None, :]\n",
        "\n",
        "    if attention_mask.dim() == 4:\n",
        "        return attention_mask.to(dtype=dtype)\n",
        "\n",
        "    return None\n",
        "\n",
        "# ============================================================\n",
        "# Patch GPT2Attention.forward (robust)\n",
        "# It replaces GPT-2’s attention forward function with a custom one that can\n",
        "# (a) collect per-head activations and\n",
        "# (b) inject ITI interventions — without breaking GPT-2.\n",
        "\n",
        "def patch_gpt2_attention_for_iti(model, iti_state: ITIState):\n",
        "\n",
        "    for layer_idx, block in enumerate(model.transformer.h):\n",
        "        attn = block.attn\n",
        "\n",
        "        # Restore if already patched\n",
        "        if hasattr(attn, \"_original_forward\"):\n",
        "            attn.forward = attn._original_forward\n",
        "        # Python looks at the object attn. It asks: \"Does this object have a property named _original_forward saved inside it?\"\n",
        "        # If Yes: It executes the next line, which resets the forward method back to its original state.\n",
        "        attn.layer_idx = layer_idx\n",
        "        attn._original_forward = attn.forward\n",
        "\n",
        "        # New attention forward\n",
        "        def iti_forward(self,\n",
        "                        hidden_states,\n",
        "                        past_key_values=None,\n",
        "                        layer_past=None,\n",
        "                        cache_position=None,\n",
        "                        attention_mask=None,\n",
        "                        head_mask=None,\n",
        "                        use_cache=False,\n",
        "                        output_attentions=False,\n",
        "                        **kwargs):\n",
        "            # HF's transformers library uses different names to hold KV cache, older versions use layer_past\n",
        "            # Newer versions like different models (Llama, Mistral, etc.) now use the variable name past_key_values\n",
        "            layer_past = past_key_values if past_key_values is not None else layer_past\n",
        "\n",
        "            # A standard Linear layer stores its weights as [out_features, in_features]\n",
        "            # GPT-2’s Conv1D layer stores weights as [in_features, out_features]\n",
        "            qkv = self.c_attn(hidden_states)\n",
        "            query, key, value = qkv.split(d_model, dim=2) # each [B,T,d_model]\n",
        "\n",
        "            # Split heads\n",
        "            q = split_heads(query, n_heads, head_dim) # [B,H,Tq,D]\n",
        "            k = split_heads(key, n_heads, head_dim)   # [B,H,Tk,D]\n",
        "            v = split_heads(value, n_heads, head_dim) # [B,H,Tk,D]\n",
        "\n",
        "            # Append cache\n",
        "            if layer_past is not None:\n",
        "                past_k, past_v = layer_past # [B,H,Tpast,D]\n",
        "                k = torch.cat([past_k, k], dim=2)\n",
        "                v = torch.cat([past_v, v], dim=2)\n",
        "\n",
        "            present = (k, v) if use_cache else None\n",
        "\n",
        "            B, H, Tq, D = q.shape\n",
        "            Tk = k.size(2)\n",
        "\n",
        "            # Scaled dot-product attention scores: [B,H,Tq,Tk]\n",
        "            scale = 1.0 / np.sqrt(D)\n",
        "            attn_scores = torch.matmul(q, k.transpose(-2, -1)) * scale\n",
        "\n",
        "            # Causal mask\n",
        "            causal = make_causal_mask(Tq, Tk, device=attn_scores.device) # [Tq,Tk]\n",
        "            attn_scores = attn_scores.masked_fill(~causal[None, None, :, :], torch.finfo(attn_scores.dtype).min)\n",
        "\n",
        "            # Add external attention mask (padding)\n",
        "            am = expand_attention_mask(attention_mask, attn_scores.dtype)\n",
        "            if am is not None:\n",
        "                # am is [B, 1, 1, Tk] additive\n",
        "                attn_scores = attn_scores + am\n",
        "\n",
        "            attn_weights = F.softmax(attn_scores, dim=-1)\n",
        "\n",
        "            # Optional head mask (rarely used)\n",
        "            if head_mask is not None:\n",
        "                # head_mask can be [H] or [L,H]; handle [H] case\n",
        "                if head_mask.dim() == 1:\n",
        "                    attn_weights = attn_weights * head_mask.view(1, -1, 1, 1)\n",
        "                elif head_mask.dim() == 2:\n",
        "                    attn_weights = attn_weights * head_mask[self.layer_idx].view(1, -1, 1, 1)\n",
        "\n",
        "            # Dropout (if exists)\n",
        "            if hasattr(self, \"attn_dropout\") and self.attn_dropout is not None:\n",
        "                attn_weights = self.attn_dropout(attn_weights)\n",
        "\n",
        "            # Head outputs: [B,H,Tq,D]\n",
        "            attn_output = torch.matmul(attn_weights, v)\n",
        "\n",
        "            # -------- Collect last-token head activations --------\n",
        "            if iti_state.collect:\n",
        "                # use original 2D mask if available, otherwise last token\n",
        "                if attention_mask is not None and attention_mask.dim() == 2:\n",
        "                    last_idx = torch.clamp(attention_mask.long().sum(dim=-1)-1, min=0)\n",
        "                # [B]\n",
        "                else:\n",
        "                    # FIX: device should be attn_output.device, not the tensor itself\n",
        "                    last_idx = torch.full((B,), Tq-1, device=attn_output.device, dtype=torch.long)\n",
        "                b = torch.arange(B, device=attn_output.device)\n",
        "                vec_bhd = attn_output[b, :, last_idx, : ] # [B,H,D]\n",
        "                # FIX: actually push to cache\n",
        "                iti_state.push(self.layer_idx, vec_bhd)\n",
        "\n",
        "            # ITI intervention in Head space -----------------------\n",
        "            if iti_state.active and iti_state.theta is not None and iti_state.selected is not None:\n",
        "                l = self.layer_idx\n",
        "                sel = iti_state.selected[l] # [H] Bool\n",
        "                if sel.any():\n",
        "                    theta_l = iti_state.theta[l] # [H,D]\n",
        "                    sigma_l = iti_state.sigma[l] # [H]\n",
        "                    delta = torch.zeros((n_heads, head_dim), device=attn_output.device, dtype=attn_output.dtype)\n",
        "                    # FIX: theta_l[sel], not theta_l(sel)\n",
        "                    delta[sel] = (iti_state.alpha * sigma_l[sel]).unsqueeze(-1) * theta_l[sel]\n",
        "                    attn_output = attn_output + delta.view(1, n_heads, 1, head_dim)\n",
        "\n",
        "            # Merge heads + output projection\n",
        "            attn_output = merge_heads(attn_output) # [B,Tq,d_model]\n",
        "            attn_output = self.c_proj(attn_output) # [B,Tq,d_model]\n",
        "            if hasattr(self, \"resid_dropout\") and self.resid_dropout is not None:\n",
        "                attn_output = self.resid_dropout(attn_output)\n",
        "            outputs = (attn_output, present)\n",
        "            if output_attentions:\n",
        "                outputs = outputs + (attn_weights,)\n",
        "            return outputs\n",
        "\n",
        "        attn.forward = types.MethodType(iti_forward, attn)\n",
        "\n",
        "patch_gpt2_attention_for_iti(model, iti)\n",
        "print(\"Patched GPT-2 attention for per-head ITI\")\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# Collect per-head activations X: [N,L,H,D] on probe dataset\n",
        "\n",
        "@torch.no_grad()\n",
        "def collect_head_activations(examples: List[ProbeExample], batch_size=16, max_length=256) -> Tuple[torch.Tensor, torch.Tensor]:\n",
        "    iti.reset_cache()\n",
        "    iti.collect = True\n",
        "    iti.active = False\n",
        "\n",
        "    ys = []\n",
        "    for i in range(0, len(examples), batch_size):\n",
        "        batch = examples[i:i+batch_size]\n",
        "        texts = [t.text for t in batch]\n",
        "        # FIX: torch.tensor instead of torch.Tensor\n",
        "        ys.append(torch.tensor([t.y for t in batch], dtype=torch.float32))\n",
        "        enc = tokenizer(texts, return_tensors=\"pt\", padding=True, truncation=True, max_length=max_length).to(device)\n",
        "        _ = model(**enc, use_cache=False, return_dict=True)\n",
        "\n",
        "    iti.collect = False\n",
        "    y = torch.cat(ys, dim=0)\n",
        "    X = iti.pop_all() # Retrieves the cached data: One big tensor of shape [B, Layers, Heads, Dim]\n",
        "    return X, y\n",
        "\n",
        "\n",
        "Xtr, ytr = collect_head_activations(probe_train, batch_size=16)\n",
        "Xva, yva = collect_head_activations(probe_val, batch_size=16)\n",
        "print(\"Xtr:\", Xtr.shape, \"ytr:\", ytr.shape)\n",
        "print(\"Xva:\", Xva.shape, \"yva:\", yva.shape)\n",
        "\n",
        "Xtr = Xtr.to(device).float()\n",
        "ytr = ytr.to(device).float()\n",
        "Xva = Xva.to(device).float()\n",
        "yva = yva.to(device).float()\n",
        "\n",
        "# Training per-head probes simultaneously\n",
        "W = nn.Parameter(torch.zeros(n_layers, n_heads, head_dim, device=device))\n",
        "bb = nn.Parameter(torch.zeros(n_layers, n_heads, device=device))\n",
        "opt = torch.optim.AdamW([W, bb], lr=2e-2)\n",
        "loss_fn = nn.BCEWithLogitsLoss()\n",
        "\n",
        "def logits_from(X):\n",
        "    return (X * W.unsqueeze(0)).sum(dim=-1) + bb.unsqueeze(0)\n",
        "\n",
        "EPOCHS = 8\n",
        "for epoch in range(1,EPOCHS+1):\n",
        "    opt.zero_grad()\n",
        "    lg = logits_from(Xtr)\n",
        "    loss = loss_fn(lg.reshape(-1), ytr.view(-1,1,1).expand_as(lg).reshape(-1))\n",
        "    loss.backward()\n",
        "    opt.step()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        va_lg = logits_from(Xva)\n",
        "        va_pred = (torch.sigmoid(va_lg)>0.5).float()\n",
        "        va_y = yva.view(-1,1,1).expand_as(va_lg)\n",
        "        head_acc = (va_pred == va_y).float().mean(dim=0) # [L,H]\n",
        "        best = head_acc.max().item()\n",
        "    print(f\"Epoch {epoch}/{EPOCHS} | loss={loss.item():.4f} | best_head_val_acc={best:.3f}\")\n",
        "\n",
        "# ============================================================\n",
        "# Select top-K heads by validation probe accuracy (sparse intervention)\n",
        "K = 48\n",
        "flat_acc = head_acc.reshape(-1)\n",
        "topk = torch.topk(flat_acc, k=min(K, flat_acc.numel()))\n",
        "# FIX: torch.bool not torch.book\n",
        "selected = torch.zeros_like(flat_acc, dtype=torch.bool)\n",
        "selected[topk.indices] = True\n",
        "selected = selected.view(n_layers, n_heads)\n",
        "print(\"Selected heads:\", int(selected.sum().item()), \"Best head acc:\", float(topk.values[0].item()))\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# Build theta (unit probe direction) and sigma (std along theta) like ITI\n",
        "with torch.no_grad():\n",
        "    theta = W.detach().clone()\n",
        "    theta = theta/(theta.norm(dim=-1, keepdim=True) + 1e-8) # [L,H,D]\n",
        "    Xall = torch.cat([Xtr,Xva], dim=0)\n",
        "    proj = (Xall * theta.unsqueeze(0)).sum(dim=-1) # [N,L,H]\n",
        "    sigma = proj.std(dim=0).clamp(min=1e-6) #[L,H]\n",
        "\n",
        "iti.theta = theta\n",
        "iti.sigma = sigma\n",
        "iti.selected = selected\n",
        "\n",
        "# ============================================================\n",
        "# Multiple-choice evaluation via conditional logprob\n",
        "\n",
        "@torch.no_grad()\n",
        "def conditional_logprob(prompt: str, completion: str) -> float:\n",
        "    full = prompt + completion\n",
        "    enc_full = tokenizer(full, return_tensors=\"pt\").to(device)\n",
        "    input_ids = enc_full[\"input_ids\"]\n",
        "    attn_mask = enc_full[\"attention_mask\"]\n",
        "    out = model(input_ids=input_ids, attention_mask=attn_mask, use_cache=False, return_dict=True)\n",
        "    logits = out.logits\n",
        "\n",
        "    logp = torch.log_softmax(logits[:, :-1, :], dim=-1)\n",
        "    target = input_ids[:, 1:]\n",
        "\n",
        "    prompt_len = tokenizer(prompt, return_tensors=\"pt\")[\"input_ids\"].shape[1]\n",
        "    start = max(prompt_len - 1, 0)\n",
        "    token_lops = logp[0, start:, :].gather(1, target[0, start:].unsqueeze(-1)).squeeze(-1)\n",
        "\n",
        "    # FIX: return the score\n",
        "    return float(token_lops.sum().item())\n",
        "\n",
        "def mc_accuracy(question_ds, max_items=200, target_key=\"mc1_targets\")-> float:\n",
        "    n = min(max_items, len(question_ds))\n",
        "    correct = 0\n",
        "    for i in range(n):\n",
        "        ex = question_ds[i]\n",
        "        q = ex[\"question\"]\n",
        "        choices = ex[target_key][\"choices\"]\n",
        "        labels = ex[target_key][\"labels\"]\n",
        "        gold = int(np.argmax(labels))\n",
        "\n",
        "        prompt = f\"Q: {q}\\nA:\"\n",
        "        scores = [conditional_logprob(prompt, \" \" + c.strip()) for c in choices]\n",
        "        pred = int(np.argmax(scores))\n",
        "\n",
        "        # FIX: update correct count\n",
        "        correct += int(pred == gold)\n",
        "\n",
        "    return correct / n\n",
        "\n",
        "# Baseline\n",
        "iti.active = False\n",
        "iti.alpha = 0.0\n",
        "base = mc_accuracy(test_q, max_items=200)\n",
        "print(\"\\nBaseline MC1 accuracy (n=200):\", base)\n",
        "\n",
        "# ITI alpha sweep\n",
        "for a in [0.0, 0.5, 1.0, 2.0, 3.0]:\n",
        "    iti.active = (a != 0.0)\n",
        "    iti.alpha = float(a)\n",
        "    acc = mc_accuracy(test_q, max_items=200)\n",
        "    print(f\"ITI alpha={a:>3}: MC1 accuracy={acc:.3f}\")"
      ],
      "metadata": {
        "id": "QTp_pDZ5ii1b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 587,
          "referenced_widgets": [
            "895c7c1daa5b4568acb7379fa20b16f6",
            "e39b22228f8a4f40b2faef991e03d5e2",
            "329b024ad50644e792ec6d4b920e20c8",
            "5aa080c103344c7fb2038c3a18e0ba59",
            "6c6951f5bbe74cee9bbc0f9e5bc24f9e",
            "488d09cf36494aac9613b5dc12f35a0b",
            "c862dbd2f253491eb53c9c967f52ab7d",
            "70408eae09ee4773a42e177d5318ed59",
            "eeb2f0fba99647b0ab598e3238e0814b",
            "d01bb3ef7eda427197540c4c01b7bc64",
            "5cdb7b252f1746ca9eac7952a2dd87af"
          ]
        },
        "outputId": "f328bd39-d42d-48f5-af7b-87699a821af0"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading weights:   0%|          | 0/292 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "895c7c1daa5b4568acb7379fa20b16f6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "GPT2LMHeadModel LOAD REPORT from: gpt2-medium\n",
            "Key                  | Status     |  | \n",
            "---------------------+------------+--+-\n",
            "h.{0...23}.attn.bias | UNEXPECTED |  | \n",
            "\n",
            "Notes:\n",
            "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers=24, Heads=16, d_model=1024, head_dim=64\n",
            "Questions train: 571 test: 246\n",
            "Probe examples: 1515 Pos rate: 0.19801980198019803\n",
            "Probe train: 1212 Probe val: 303\n",
            "Patched GPT-2 attention for per-head ITI\n",
            "Xtr: torch.Size([1212, 24, 16, 64]) ytr: torch.Size([1212])\n",
            "Xva: torch.Size([303, 24, 16, 64]) yva: torch.Size([303])\n",
            "Epoch 1/8 | loss=0.6931 | best_head_val_acc=0.802\n",
            "Epoch 2/8 | loss=0.6624 | best_head_val_acc=0.802\n",
            "Epoch 3/8 | loss=0.6364 | best_head_val_acc=0.802\n",
            "Epoch 4/8 | loss=0.6138 | best_head_val_acc=0.802\n",
            "Epoch 5/8 | loss=0.5944 | best_head_val_acc=0.802\n",
            "Epoch 6/8 | loss=0.5777 | best_head_val_acc=0.802\n",
            "Epoch 7/8 | loss=0.5636 | best_head_val_acc=0.802\n",
            "Epoch 8/8 | loss=0.5519 | best_head_val_acc=0.802\n",
            "Selected heads: 48 Best head acc: 0.801980197429657\n",
            "\n",
            "Baseline MC1 accuracy (n=200): 0.22\n",
            "ITI alpha=0.0: MC1 accuracy=0.220\n",
            "ITI alpha=0.5: MC1 accuracy=0.225\n",
            "ITI alpha=1.0: MC1 accuracy=0.230\n",
            "ITI alpha=2.0: MC1 accuracy=0.235\n",
            "ITI alpha=3.0: MC1 accuracy=0.240\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Hoq6d9WLE8_o"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}